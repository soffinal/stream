# @soffinal/stream - LLM Context

## Library Overview

@soffinal/stream is a TypeScript library providing multi-paradigm reactive primitives. It unifies functional reactive programming (FRP), event-driven architecture, dataflow programming, and data-driven programming with native support for parallel (Web Workers) and distributed (network) execution.

## Core Philosophy

**Multi-paradigm by design**: Stream supports multiple programming paradigms simultaneously. You can combine FRP, event-driven, dataflow, and data-driven patterns in the same pipeline.

**Execution agnostic**: Same code runs locally (main thread), in parallel (Web Workers), or distributed (network). Execution context is independent of programming paradigm.

**Minimal primitive**: 1 core concept (Stream). Everything else is composition.

> "The primitive is powerful enough to implement itself. This is the elegance of minimal abstractions."

## Paradigm Support

### Functional Reactive Programming (FRP)
```typescript
stream.pipe(filter(x => x > 0)).pipe(map(x => x * 2))
```
Pure functions, immutable transformations, declarative pipelines.

### Event-Driven Architecture
```typescript
stream.listen(handler);
stream.push(event);
```
Decoupled components, pub/sub patterns, reactive systems.

### Dataflow Programming
```typescript
streamA.pipe(merge(streamB)).pipe(zip(streamC))
```
Visual graphs, data flows through nodes, composable pipelines.

### Data-Driven Programming
```typescript
stream.pipe(map(x => ({ value: x, predicate: ... }))).pipe(filter)
```
Configuration as data, runtime reconfiguration, self-describing events.

### Paradigm Composition

All paradigms work together in the same pipeline:

```typescript
const configStream = new Stream<Config>();  // Event-Driven
const dataStream = new Stream<Data>();      // Event-Driven

dataStream
  .pipe(zip(configStream))                  // Dataflow
  .pipe(map(([data, config]) => ({          // Data-Driven
    value: data,
    predicate: config.filterFn,
    execution: 'parallel'
  })))
  .pipe(filter)                             // FRP
  .pipe(expose({ name: 'api' }))            // Distributed
  .listen(handler);                         // Event-Driven
```

## Execution Contexts

All paradigms work across execution contexts:

- **Local** (main thread) - Default
- **Parallel** (Web Workers) - `{ execution: 'parallel' }`
- **Distributed** (network) - `expose()` / `remote()`

Execution context is orthogonal to paradigm choice.

## Core Primitives

### Stream<T>

The fundamental building block. A stream can:
- **Push values**: `stream.push(value1, value2, ...)`
- **Listen to values**: `stream.listen((value) => { ... })`
- **Async iterate**: `for await (const value of stream) { ... }`
- **Transform**: `stream.pipe(transformer)`

### Constructor Patterns

```typescript
// Empty stream (push-based)
new Stream<T>()

// Async generator (pull-based, lazy)
// Executes only when first listener is added
// Stops automatically when all listeners are removed
new Stream<T>(async function* () {
  for await (const value of source) {
    yield value;
  }
})

// From another stream
new Stream<T>(sourceStream)
```

## Transformer Architecture

### What is a Transformer?

A transformer is a function that takes a stream and returns a new stream:

```typescript
type Transformer<T, U> = (source: Stream<T>) => Stream<U>
```

### Simple Transformers (Composable from Primitives)

Use existing transformers like `map`, `filter`:

```typescript
// Take first N values
const take = <T>(n: number) =>
  filter<T, { count: number }>({ count: 0 }, (state, value) => {
    if (state.count >= n) return;
    return [true, { count: state.count + 1 }];
  });

// Running sum
const scan = <T, U>(fn: (acc: U, value: T) => U, initial: U) =>
  map<T, { acc: U }, U>({ acc: initial }, (state, value) => {
    const newAcc = fn(state.acc, value);
    return [newAcc, { acc: newAcc }];
  });
```

### Complex Transformers (Self-Referential Pattern)

For event-driven logic or async coordination, use the self-referential pattern:

```typescript
const debounce = <T>(ms: number) => (source: Stream<T>) => {
  return new Stream<T>(async function* () {
    const output = new Stream<T>();  // Stream creates Stream
    let timer: any = null;

    const abort = source.listen((value) => {
      clearTimeout(timer);
      timer = setTimeout(() => output.push(value), ms);
    });

    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      clearTimeout(timer);
    }
  });
};
```

**Key insight**: Create internal output stream, listen to source, push to output, iterate output. Generator lifecycle manages listener lifecycle with automatic cleanup.

## Core Transformers (11 total)

### Stateful Transformers

**state** - Reactive state with `.state.value` getter/setter
**gate** - Flow control with `.gate.open()`, `.gate.close()`
**cache** - HOT caching with `.cache.values`, TTL, drop strategies

### Value Transformers

**filter** - Remove values based on predicate (sync/async, stateful)
**map** - Transform values (sync/async, stateful)
**flat** - Flatten arrays into individual values
**buffer** - Collect values into arrays of specified size

### Combination Transformers

**merge** - Combine multiple streams (union types)
**zip** - Combine streams pairwise (tuples)

### Utility Transformers

**branch** - Forward values to target stream (parallel observation)
**effect** - Side effects without transformation (identity map)

## Transformer Patterns

### Stateful Filter/Map

Both `filter` and `map` support stateful operations:

```typescript
// Stateful filter
filter<T, STATE>({ initialState }, (state, value) => {
  // Return undefined to terminate stream
  // Return [boolean, newState] to continue
  return [shouldPass, newState];
})

// Stateful map
map<T, STATE, U>({ initialState }, (state, value) => {
  return [mappedValue, newState];
})
```

### Self-Referential Pattern (for event-driven transformers)

**When to use:**
- Event-driven logic (can't yield from callbacks)
- Async coordination (debounce, throttle, ordered execution)
- Need guaranteed cleanup (timers, listeners, resources)
- Eliminate manual state tracking

**Pattern:**
```typescript
const transformer = <T, U>(...) => (source: Stream<T>) => {
  return new Stream<U>(async function* () {
    const output = new Stream<U>();
    
    const abort = source.listen((value) => {
      // Event-driven logic that can't yield
      output.push(transformedValue);
    });
    
    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      // Cleanup resources
    }
  });
};
```

**Key features:**
- Stream creates Stream - the primitive implements itself
- Generator lifecycle manages listener lifecycle
- Automatic cleanup via finally block
- No manual coordination (no pendings, resolve functions, state tracking)
- Eliminates 20+ lines of manual coordination code

## Strategy Options

`filter`, `map`, and `effect` support execution strategy options:

- **sequential** (default): Process one at a time on main thread
- **concurrent**: Process all concurrently on main thread, emit as completed (unordered)
- **concurrent-ordered**: All execute concurrently (events don't wait), emit in order. When computations have equal or incremental execution time, performance equals concurrent.
- **parallel**: Process in Web Workers, emit as completed (unordered)
- **parallel-ordered**: All execute in parallel (events don't wait), emit in order. When computations have equal or incremental execution time, performance equals parallel.

**Performance insight**: Ordered strategies only buffer when newer events finish before older ones. When execution times are equal or incremental (each takes same or slightly more time), results naturally arrive in order with zero buffering overhead.

```typescript
// Main thread, ordered - all computations start immediately
stream.pipe(map(async (v) => await process(v), { 
  execution: 'concurrent-ordered' 
}))

// Workers, unordered (fastest)
stream.pipe(map((v) => heavyComputation(v), { 
  execution: 'parallel' 
}))

// Workers, ordered - all computations start immediately in workers
stream.pipe(map((v) => heavyComputation(v), { 
  execution: 'parallel-ordered' 
}))

// Workers with args
stream.pipe(map((v, args) => v * args.multiplier, { 
  execution: 'parallel',
  args: { multiplier: 2 }
}))
```

## Worker Pool Architecture

### Overview

The library includes a singleton WorkerPool that manages Web Workers for CPU-intensive operations:

- **Shared pool**: Configurable workers (default: 4) shared across all streams
- **Function registration**: Functions registered once, not serialized per event
- **Automatic fallback**: Falls back to main thread if workers unavailable
- **Round-robin**: Load balancing across workers

### Configuration

```typescript
// Configure based on your hardware
Stream.configure({ workerPoolSize: 8 }); // Default: 4

// High-end hardware
Stream.configure({ workerPoolSize: 16 });

// Restricted hardware (IoT, embedded)
Stream.configure({ workerPoolSize: 2 });

// Get current config
const config = Stream.getConfig();
console.log(config.workerPoolSize);
```

### How It Works

```typescript
// Worker pool registers function once
const { execute } = WorkerPool.register(mapper, args);

// Only values sent per event
stream.listen((value) => {
  execute(value).then(result => output.push(result));
});
```

### Benefits

- ✅ Function serialized once (not per event)
- ✅ Args cached in workers
- ✅ Smaller messages (just value)
- ✅ Better performance for high-frequency streams
- ✅ No worker limit issues (pool manages resources)

### Composition Pattern

**Key insight**: `map` is the execution engine. Other transformers compose with it:

```typescript
// filter composes with map
export const filter = <T>(predicate, options) => (source) => {
  const mapped = source.pipe(
    map(async (value) => [value, await predicate(value)], options)
  );
  
  return new Stream(async function* () {
    for await (const [value, shouldPass] of mapped) {
      if (shouldPass) yield value;
    }
  });
};

// effect composes with map
export const effect = <T>(fn, options) => (source) => 
  source.pipe(map(async (value) => {
    await fn(value);
    return value;  // Identity
  }, options));
```

This means all execution strategies (sequential, concurrent, parallel) work automatically in filter and effect!

## Common Patterns

### Dynamic Configuration Pattern

Transformers support both **static** (args) and **dynamic** (event properties) configuration:

```typescript
// Static: Config at construction
stream.pipe(filter(x => x > 5))

// Dynamic: Config from events
stream
  .pipe(map(x => ({ value: x, predicate: (v) => v > 5 })))
  .pipe(filter)  // No args = reads event.predicate
```

**Convention:**
- `transformer(args)` = Static configuration
- `transformer` (no args) = Dynamic configuration (reads from event)

**Implementation pattern:**
```typescript
// Overloaded signatures
export function filter<T>(predicate: (v: T) => boolean): Transformer<T, T>;
export function filter<T extends { predicate: Function }>(): Transformer<T, T['value']>;

export function filter<T>(predicate?: (v: T) => boolean) {
  return (stream: Stream<T>) => {
    return new Stream(async function* () {
      for await (const value of stream) {
        const pred = predicate ?? (value as any).predicate;
        const val = predicate ? value : (value as any).value;
        
        if (await pred(val)) yield predicate ? value : val;
      }
    });
  };
}
```

**Single map configures pipeline:**
```typescript
stream
  .pipe(map(event => ({
    value: event.data,
    predicate: (v) => v > event.threshold,
    mapper: (v) => v * event.multiplier,
    size: event.urgent ? 1 : 50
  })))
  .pipe(filter)   // Uses event.predicate
  .pipe(map)      // Uses event.mapper
  .pipe(buffer)   // Uses event.size
```

**Type safety:**
TypeScript enforces the entire pipeline contract at compile time. Errors appear exactly where contracts break:

```typescript
// ✅ Valid
stream
  .pipe(map(x => ({ value: x, predicate: ... })))
  .pipe(filter)  // Has predicate

// ❌ Error at filter
stream
  .pipe(map(x => ({ value: x })))
  .pipe(filter)  // Missing predicate property

// ❌ Error at map - buffer creates boundary
stream
  .pipe(map(x => ({ value: x, predicate: ..., mapper: ... })))
  .pipe(filter)
  .pipe(buffer)  // Returns T[] - config lost
  .pipe(map)     // T[] doesn't have mapper
```

**Pipeline boundaries:**
Transformers that change structure (buffer, flat, zip, merge) create boundaries where config is lost. User must reshape:

```typescript
stream
  .pipe(filter)
  .pipe(buffer)   // Boundary - returns T[]
  .pipe(map(arr => ({ value: arr, mapper: ... })))  // Reshape
  .pipe(map)      // ✅ Works
```

**Use cases:**
- Adaptive rate limiting (premium vs free users)
- Dynamic routing (event.destination)
- Per-event execution strategy (urgent vs normal)
- Multi-tenant processing (per-tenant config)
- A/B testing (experiment-specific algorithms)
- Self-describing events (carry processing instructions)

**Key insight**: Events become instructions. Streams become programmable execution engines.

### Self-Referential Pattern

**Canonical example** - concurrent-ordered execution from map transformer:

```typescript
const concurrentOrdered = <T, U>(mapper: (value: T) => Promise<U>) => {
  return (source: Stream<T>) => {
    return new Stream<U>(async function* () {
      const output = new Stream<Promise<U>>();  // Stream creates Stream

      const abort = source.listen((value) => {
        output.push(mapper(value));  // Push promises immediately
      });

      try {
        for await (const mapped of output) {
          yield await mapped;  // Await in order
        }
      } finally {
        abort();  // Automatic cleanup
      }
    });
  };
};
```

**Why this is genius:**
- Eliminates coordination complexity (no pendings array, resolve functions, state tracking)
- Maintains order naturally (async iteration awaits sequentially)
- Automatic cleanup via generator lifecycle
- 11 lines vs 20+ with manual coordination
- Self-documenting code

**Compare to manual approach:**
```typescript
// Manual (20+ lines)
const pendings: Promise<U>[] = [];
let resolve: Function | undefined;
source.listen((value) => {
  pendings.push(mapper(value));
  resolve?.();
});
while (true) {
  if (pendings.length) yield await pendings.shift()!;
  else await new Promise((r) => (resolve = r));
}

// Self-referential (11 lines)
const output = new Stream<Promise<U>>();
source.listen((value) => output.push(mapper(value)));
for await (const mapped of output) yield await mapped;
```

**When to use:**
- Event-driven logic (can't yield from callbacks)
- Async coordination (debounce, throttle, ordered execution)
- Need guaranteed cleanup (timers, listeners, resources)
- Eliminate manual state tracking

**Pattern template:**
```typescript
const transformer = <T, U>(...) => (source: Stream<T>) => {
  return new Stream<U>(async function* () {
    const output = new Stream<U>();
    
    const abort = source.listen((value) => {
      // Event-driven logic that can't yield
      output.push(transformedValue);
    });
    
    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      // Cleanup resources
    }
  });
};
```

The primitive is powerful enough to implement itself. This is the elegance of minimal abstractions.

### Timing Patterns

```typescript
// Debounce - delay until quiet (self-referential pattern)
const debounce = <T>(ms: number) => (source: Stream<T>) => {
  return new Stream<T>(async function* () {
    const output = new Stream<T>();
    let timer: any = null;

    const abort = source.listen((value) => {
      clearTimeout(timer);
      timer = setTimeout(() => output.push(value), ms);
    });

    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      clearTimeout(timer);
    }
  });
};

// Delay - delay each value (simple iteration)
const delay = <T>(ms: number) => (source: Stream<T>) =>
  new Stream<T>(async function* () {
    for await (const value of source) {
      await new Promise(resolve => setTimeout(resolve, ms));
      yield value;
    }
  });

// Window - time-based windowing (self-referential pattern)
const window = <T>(ms: number) => (source: Stream<T>) => {
  return new Stream<T[]>(async function* () {
    const output = new Stream<T[]>();
    let buffer: T[] = [];
    
    const flush = () => {
      if (buffer.length > 0) {
        output.push([...buffer]);
        buffer = [];
      }
    };
    
    const timer = setInterval(flush, ms);
    const abort = source.listen((value) => buffer.push(value));

    try {
      for await (const batch of output) {
        yield batch;
      }
    } finally {
      clearInterval(timer);
      abort();
      flush();
    }
  });
};
```

### State Management Patterns

```typescript
// Take first N
const take = <T>(n: number) =>
  filter<T, { count: number }>({ count: 0 }, (state, value) => {
    if (state.count >= n) return;
    return [true, { count: state.count + 1 }];
  });

// Throttle (rate limit)
const throttle = <T>(ms: number) =>
  filter<T, { lastEmit: number }>({ lastEmit: 0 }, (state, value) => {
    const now = Date.now();
    if (now - state.lastEmit < ms) return [false, state];
    return [true, { lastEmit: now }];
  });

// Distinct (deduplicate)
const distinct = <T>() =>
  filter<T, { seen: Set<T> }>({ seen: new Set() }, (state, value) => {
    if (state.seen.has(value)) return [false, state];
    state.seen.add(value);
    return [true, state];
  });
```

## Design Principles

1. **Minimal primitives**: 2 primitives (Stream + pipe), 11 transformers
2. **Composability**: Build complex from simple
3. **Type safety**: Full TypeScript inference
4. **Lazy by default**: Transformers don't start until consumed
5. **Automatic cleanup**: WeakRef, AbortSignal, disposable pattern
6. **Efficient**: Transformers execute once per value, shared computation

## Creating New Transformers

### Decision Tree

1. **Can it be composed from existing transformers?**
   - Yes → Create as pattern using `filter`, `map`, etc.
   - No → Continue

2. **Does it need event-driven logic or async coordination?**
   - Yes → Use self-referential pattern
   - No → Continue

3. **Does it need special API (like `.state.value`)?**
   - Yes → Create as core transformer with extended type
   - No → Use simple async generator with `for await`

### Testing Checklist

- [ ] Basic functionality
- [ ] Edge cases (empty, single value, rapid emissions)
- [ ] Lazy initialization
- [ ] Cleanup (no memory leaks)
- [ ] Type safety

## Common Mistakes

1. **Don't iterate output in its own generator** - creates circular dependency
2. **Use `output.push()` not `yield`** - when you need async timing control
3. **Remember stateful operations are always sequential** - no strategy option
4. **Clean up timers/intervals** - in finally block or when generator stops
5. **Use WeakRef for DOM element contexts** - automatic cleanup on GC

## Examples

### Simple Pattern (Composable)

```typescript
// Skip first N values
export const skip = <T>(n: number) =>
  filter<T, { count: number }>({ count: 0 }, (state, value) => {
    const newCount = state.count + 1;
    return [newCount > n, { count: newCount }];
  });
```

### Complex Pattern (Self-Referential)

```typescript
// Audit - emit first, ignore until quiet
export const audit = <T>(ms: number) => (source: Stream<T>) => {
  return new Stream<T>(async function* () {
    const output = new Stream<T>();
    let timer: any = null;
    let canEmit = true;

    const abort = source.listen((value) => {
      if (canEmit) {
        output.push(value);
        canEmit = false;
        clearTimeout(timer);
        timer = setTimeout(() => (canEmit = true), ms);
      }
    });

    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      clearTimeout(timer);
    }
  });
};
```

### Core Transformer (Extended Type)

```typescript
type Gate<T> = Stream<T> & {
  gate: {
    open(): void;
    close(): void;
    readonly isOpen: boolean;
  };
};

export const gate = <T>(): Stream.Transformer<Stream<T>, Gate<T>> => {
  return (source: Stream<T>) => {
    let isOpen = true;
    
    const output = new Stream<T>(async function* () {
      for await (const value of source) {
        if (isOpen) yield value;
      }
    }) as Gate<T>;

    output.gate = {
      open: () => (isOpen = true),
      close: () => (isOpen = false),
      get isOpen() { return isOpen; }
    };

    return output;
  };
};
```

## File Structure

```
src/
  stream.ts              # Core Stream class
  transformers/
    state/
      state.ts           # Transformer implementation
      state.md           # Documentation
      state.test.ts      # Tests
    [transformer]/
      index.ts           # Export
patterns/
  [pattern]/
    [pattern].ts         # Pattern implementation
    [pattern].test.ts    # Tests
```

## Documentation Template

```typescript
/**
 * [One-line description]
 * 
 * @example
 * ```typescript
 * stream.pipe([pattern](args))
 * ```
 */
```

## This Context File

Use this file to:
- Understand library architecture
- Create new patterns/transformers
- Assist users with library usage
- Generate examples and documentation
- Debug issues

The library is designed for simplicity and composability. When in doubt, check if it can be composed from existing primitives before creating new ones.
