# @soffinal/stream - LLM Context

## Library Overview

@soffinal/stream is a TypeScript library providing multi-paradigm reactive primitives. It unifies functional reactive programming (FRP), event-driven architecture, dataflow programming, and data-driven programming with native support for parallel (Web Workers) and distributed (network) execution.

## Core Philosophy

**Multi-paradigm by design**: Stream supports multiple programming paradigms simultaneously. You can combine FRP, event-driven, dataflow, and data-driven patterns in the same pipeline.

**Execution agnostic**: Same code runs locally (main thread), in parallel (Web Workers), or distributed (network). Execution context is independent of programming paradigm.

**Minimal primitive**: 1 core concept (Stream). Everything else is composition.

> "The primitive is powerful enough to implement itself. This is the elegance of minimal abstractions."

## Core Primitives

### Stream<VALUE>

The fundamental building block. A stream can:
- **Push values**: `stream.push(value1, value2, ...)`
- **Listen to values**: `stream.listen((value) => { ... })` - Returns Controller
- **Async iterate**: `for await (const value of stream) { ... }`
- **Transform**: `stream.pipe(transformer)`

### Constructor Patterns

```typescript
// Empty stream (push-based)
new Stream<T>()

// Async generator (pull-based, lazy)
// Executes only when first listener is added
// Stops automatically when all listeners are removed
new Stream<T>(async function* () {
  for await (const value of source) {
    yield value;
  }
})

// Callback-based (FunctionSource pattern)
// For event-driven sources with cleanup
new Stream<T>((push, onAbort, output) => {
  const interval = setInterval(() => push(Date.now()), 1000);
  onAbort(() => clearInterval(interval));
})

// From another stream
new Stream<T>(sourceStream)
```

### Stream.Controller

Enhanced AbortController that IS a Stream<void>:
- `controller.abort()` - Abort the listener
- `controller.aborted` - Boolean property
- `controller.pipe(...)` - Pipeable lifecycle (it's a Stream!)
- Implements `Disposable` for `using` syntax

**Key insight**: Controller being a Stream enables reactive lifecycle management.

```typescript
const ctrl = stream.listen(handler);
ctrl.pipe(effect(() => cleanup())).listen(() => done());
ctrl.abort(); // Triggers cleanup chain
```

## Transformer Architecture

### What is a Transformer?

A transformer is a function that takes a stream and returns a new stream:

```typescript
type Transformer<T, U> = (source: T) => U
```

Where T and U extend Stream<any>.

### Capability Preservation System

**Key innovation**: `pipe()` automatically preserves and merges capabilities from both input and output streams.

```typescript
const stream = new Stream<number>();
const s1 = stream.pipe(state(0));      // Has .state
const s2 = s1.pipe(gate());            // Has .state AND .gate
const s3 = s2.pipe(cache());           // Has .state, .gate, AND .cache
```

**How it works**:
1. Transformers add capabilities as direct properties (e.g., `output.state = {...}`)
2. `pipe()` copies all properties from source to output at runtime
3. Type system merges capabilities from both input and output
4. Result: Full type inference with zero manual merging

**Type signature**:
```typescript
pipe<OUTPUT extends Stream<any>>(
  transformer: Stream.Transformer<this, OUTPUT>
): Stream<Stream.ValueOf<OUTPUT>> & 
   Prettify<Omit<this, keyof Stream<any>> & Omit<OUTPUT, keyof Stream<any>>>
```

### Execution Strategies (Primitives)

Execution strategies are standalone transformers that handle async coordination:

- **sequential** - Process one at a time, main thread
- **concurrent** - All execute concurrently, emit as completed (unordered)
- **concurrent-ordered** - All execute concurrently, emit in order
- **parallel** - Process in Web Workers, emit as completed (unordered)
- **parallel-ordered** - All execute in parallel, emit in order

```typescript
stream
  .pipe(sequential((x) => x * 2))
  .pipe(concurrent(async (x) => await fetch(x)))
  .pipe(parallel((x) => heavyComputation(x)))
```

**Performance insight**: Ordered strategies only buffer when newer events finish before older ones. When execution times are equal or incremental, results naturally arrive in order with zero buffering overhead.

### Logic Transformers (Simple & Synchronous)

Logic transformers should be simple, synchronous operations that compose with execution strategies:

- **filter** - Remove values based on predicate
- **effect** - Side effects without transformation (identity)
- **flat** - Flatten arrays into individual values
- **buffer** - Collect values into arrays
- **merge** - Combine multiple streams
- **zip** - Combine streams pairwise
- **branch** - Forward values to target stream
- **bind** - Bi-directional sync between streams

And many more patterns: take, skip, distinct, throttle, debounce, delay, scan, pluck, etc.

### Stateful Transformers (Capabilities)

Transformers that add special APIs via capabilities:

- **state** - Adds `.state.value` getter/setter for reactive state
- **gate** - Adds `.gate.open()`, `.gate.close()`, `.gate.isOpen` for flow control
- **cache** - Adds `.cache.values`, `.cache.size`, `.cache.clear()` for HOT caching

```typescript
const s = stream
  .pipe(state(0))      // Adds .state capability
  .pipe(gate());       // Adds .gate capability (preserves .state)

s.state.value = 5;     // ✅ Works
s.gate.close();        // ✅ Works
```

## Core Transformers

### Execution Strategies

**sequential(mapper)** - One at a time, main thread
**concurrent(mapper)** - All concurrently, unordered
**concurrent-ordered(mapper)** - All concurrently, ordered
**parallel(mapper, ...args)** - Workers, unordered
**parallel-ordered(mapper, ...args)** - Workers, ordered

### Logic Transformers

**filter(predicate)** - Remove values
**effect(callback)** - Side effects (identity map)
**flat(depth?)** - Flatten arrays
**buffer(size)** - Collect into arrays
**merge(...streams)** - Combine streams (union types)
**zip(...streams)** - Combine pairwise (tuples)
**branch(target)** - Forward to target stream
**bind(other, ...others)** - Bi-directional sync

### Capability Transformers

**state(initialValue)** - Reactive state with `.state.value`
**gate()** - Flow control with `.gate.open()`, `.gate.close()`
**cache(options?)** - HOT caching with `.cache.values`
**snapshot(name)** - Capture stream at any point for multi-level access

### Common Patterns (Composable)

```typescript
// Take first N
const take = <T>(n: number) =>
  filter<T, { count: number }>({ count: 0 }, (state, value) => {
    if (state.count >= n) return;
    return [true, { count: state.count + 1 }];
  });

// Skip first N
const skip = <T>(n: number) =>
  filter<T, { count: number }>({ count: 0 }, (state, value) => {
    const newCount = state.count + 1;
    return [newCount > n, { count: newCount }];
  });

// Distinct (deduplicate)
const distinct = <T>() =>
  filter<T, { seen: Set<T> }>({ seen: new Set() }, (state, value) => {
    if (state.seen.has(value)) return [false, state];
    state.seen.add(value);
    return [true, state];
  });

// Running sum
const scan = <T, U>(fn: (acc: U, value: T) => U, initial: U) =>
  map<T, { acc: U }, U>({ acc: initial }, (state, value) => {
    const newAcc = fn(state.acc, value);
    return [newAcc, { acc: newAcc }];
  });
```

## Self-Referential Pattern

**When to use:**
- Event-driven logic (can't yield from callbacks)
- Async coordination (debounce, throttle, ordered execution)
- Need guaranteed cleanup (timers, listeners, resources)
- Eliminate manual state tracking

**Pattern template:**
```typescript
const transformer = <T, U>(...) => (source: Stream<T>) => {
  return new Stream<U>(async function* () {
    const output = new Stream<U>();
    
    const abort = source.listen((value) => {
      // Event-driven logic that can't yield
      output.push(transformedValue);
    });
    
    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      // Cleanup resources
    }
  });
};
```

**Canonical example** - concurrent-ordered execution:

```typescript
const concurrentOrdered = <T, U>(mapper: (value: T) => Promise<U>) => {
  return (source: Stream<T>) => {
    return new Stream<U>(async function* () {
      const output = new Stream<Promise<U>>();  // Stream creates Stream

      const abort = source.listen((value) => {
        output.push(mapper(value));  // Push promises immediately
      });

      try {
        for await (const mapped of output) {
          yield await mapped;  // Await in order
        }
      } finally {
        abort();
      }
    });
  };
};
```

**Why this is genius:**
- Eliminates coordination complexity (no pendings array, resolve functions, state tracking)
- Maintains order naturally (async iteration awaits sequentially)
- Automatic cleanup via generator lifecycle
- 11 lines vs 20+ with manual coordination
- Self-documenting code

The primitive is powerful enough to implement itself.

## Worker Pool Architecture

### Overview

Singleton WorkerPool manages Web Workers for CPU-intensive operations:

- **Shared pool**: Configurable workers (default: 4)
- **Function registration**: Functions registered once, not serialized per event
- **Automatic fallback**: Falls back to main thread if workers unavailable
- **Round-robin**: Load balancing across workers

### Configuration

```typescript
// Configure based on hardware
Stream.config = { workerPoolSize: 8 }; // Default: 4

// Get current config
const config = Stream.config;
console.log(config.workerPoolSize);
```

### Auto-bind Configuration

```typescript
// Default: Convenience (auto-bind enabled)
Stream.config = { autoBind: true };
const stream = new Stream<number>();
source.listen(stream.push); // Works!

// Performance: Manual binding (auto-bind disabled)
Stream.config = { autoBind: false };
const stream = new Stream<number>();
source.listen(stream.push.bind(stream)); // Must bind

// Trade-off:
// autoBind: true  → ~600 bytes per stream, zero mental overhead
// autoBind: false → zero overhead, must remember to bind
```

## Common Patterns

### Timing Patterns

```typescript
// Debounce - delay until quiet (self-referential)
const debounce = <T>(ms: number) => (source: Stream<T>) => {
  return new Stream<T>(async function* () {
    const output = new Stream<T>();
    let timer: any = null;

    const abort = source.listen((value) => {
      clearTimeout(timer);
      timer = setTimeout(() => output.push(value), ms);
    });

    try {
      for await (const value of output) {
        yield value;
      }
    } finally {
      abort();
      clearTimeout(timer);
    }
  });
};

// Delay - delay each value (simple iteration)
const delay = <T>(ms: number) => (source: Stream<T>) =>
  new Stream<T>(async function* () {
    for await (const value of source) {
      await new Promise(resolve => setTimeout(resolve, ms));
      yield value;
    }
  });
```

### Forwarding Pattern

```typescript
// Verbose
source.listen((value) => target.push(value));

// Concise - bind push method
source.listen(target.push.bind(target));

// Why .bind()? push is on prototype (shared for memory efficiency)
// Binding ensures 'this' refers to target stream
```

### Bi-directional Sync (bind transformer)

```typescript
// Keep pipeline alive while syncing with external streams
source
  .pipe(bind(externalStream1, externalStream2))
  .pipe(filter(x => x > 0))
  .listen(console.log);

// source ↔ externalStream1 ↔ externalStream2 (all synced)
// Values continue through pipeline
// Automatic cleanup when pipeline stops
```

**Key benefit**: Avoids manual cleanup and breaking the pipeline flow.

## Design Principles

1. **Minimal primitives**: 1 primitive (Stream), infinite patterns
2. **Composability**: Build complex from simple
3. **Type safety**: Full TypeScript inference with capability preservation
4. **Lazy by default**: Generators execute only when first listener is added
5. **Automatic cleanup**: WeakRef, AbortSignal, Controller, disposable pattern
6. **Efficient**: Shared worker pool, function registration, minimal overhead

## Creating New Transformers

### Decision Tree

1. **Can it be composed from existing transformers?**
   - Yes → Create as pattern using filter, sequential, concurrent, etc.
   - No → Continue

2. **Does it need event-driven logic or async coordination?**
   - Yes → Use self-referential pattern
   - No → Continue

3. **Does it need special API (like `.state.value`)?**
   - Yes → Create as capability transformer with extended type
   - No → Use simple async generator with `for await`

### Testing Checklist

- [ ] Basic functionality
- [ ] Edge cases (empty, single value, rapid emissions)
- [ ] Lazy initialization
- [ ] Cleanup (no memory leaks)
- [ ] Type safety
- [ ] Capability preservation (if applicable)

## Common Mistakes

1. **Don't iterate output in its own generator** - creates circular dependency
2. **Use `output.push()` not `yield`** - when you need async timing control
3. **Clean up timers/intervals** - in finally block or when generator stops
4. **Use WeakRef for DOM element contexts** - automatic cleanup on GC
5. **Remember capability preservation is automatic** - just add properties to output

## All Values Are Valid

Stream treats `undefined` and `null` as valid data, never as control flow signals:

```typescript
stream.push(undefined); // ✅ Valid data
stream.push(null);      // ✅ Valid data
stream.push(0);         // ✅ Valid data
stream.push(false);     // ✅ Valid data
stream.push("");        // ✅ Valid data
```

**Why**: Values are opaque data. Stream never checks `if (value)`.

## File Structure

```
src/
  stream.ts              # Core Stream class
  transformers/
    [transformer]/
      [transformer].ts   # Implementation
      [transformer].md   # Documentation (optional)
      [transformer].test.ts # Tests
      index.ts           # Export
```

## This Context File

Use this file to:
- Understand library architecture
- Create new patterns/transformers
- Assist users with library usage
- Generate examples and documentation
- Debug issues

The library is designed for simplicity and composability. When in doubt, check if it can be composed from existing primitives before creating new ones.

## snapshot Transformer - The Killer Feature

**snapshot** is the most powerful transformer in the library. It captures the entire stream at any point in the pipeline, enabling:

### Multi-Level Injection
```typescript
const s = new Stream<number>()
  .pipe(filter(v => v > 0))
  .pipe(snapshot("filtered"))
  .pipe(map(v => v * 2))
  .pipe(snapshot("doubled"));

// Inject at any level
s.push(100);              // Bypasses all transformers
s.doubled.push(50);       // Bypasses last map
s.filtered.push(5);       // Goes through both maps
```

### Multi-Level Observation
```typescript
const pipeline = new Stream<Data>()
  .pipe(parse())
  .pipe(snapshot("parsed"))
  .pipe(validate())
  .pipe(snapshot("validated"));

// Observe at any stage
pipeline.parsed.listen(logParsed);
pipeline.validated.listen(logValidated);
pipeline.listen(logFinal);
```

### Parallel Branches from Any Point
```typescript
const main = new Stream<Event>()
  .pipe(filter(x => x.valid))
  .pipe(snapshot("filtered"))
  .pipe(map(x => x.data));

// Branch from filtered point
main.filtered
  .pipe(map(x => x.metadata))
  .listen(sendToAnalytics);
```

### Control Flow Patterns

**Replay (Time-Travel)**
```typescript
const s = new Stream<Event>()
  .pipe(cache())
  .pipe(snapshot("checkpoint"));

// Replay from checkpoint
s.checkpoint.cache.values.forEach(event => 
  s.checkpoint.push(event)
);
```

**Catch (Error Recovery)**
```typescript
const s = new Stream<Data>()
  .pipe(validate())
  .pipe(snapshot("validated"))
  .pipe(riskyOperation());

s.listen(
  data => console.log('Success:', data),
  error => s.validated.push(lastValidData) // Retry from checkpoint
);
```

**Goto (Jump to Any Point)**
```typescript
const flow = new Stream<State>()
  .pipe(step1())
  .pipe(snapshot("after_step1"))
  .pipe(step2())
  .pipe(snapshot("after_step2"));

if (needsRetry) {
  flow.after_step1.push(state); // Jump to step2
}
```

**Checkpoint-Restore**
```typescript
const editor = new Stream<Document>()
  .pipe(state(initialDoc))
  .pipe(snapshot("checkpoint"));

const saved = editor.checkpoint.state.value;
// ... edits ...
editor.state.value = saved; // Restore
```

**Undo/Redo**
```typescript
const editor = new Stream<Action>()
  .pipe(state([]))
  .pipe(snapshot("history"));

const undoStack: any[] = [];
function undo() {
  if (undoStack.length) {
    editor.state.value = undoStack.pop();
  }
}
```

### Nested Snapshots (Capability Tree)

```typescript
const s = new Stream<number>()
  .pipe(state(0))
  .pipe(snapshot("v1"))
  .pipe(map(v => v * 2))
  .pipe(state(0))
  .pipe(snapshot("v2"))
  .pipe(map(v => v + 10))
  .pipe(state(0))
  .pipe(snapshot("v3"));

// Access any point in history
s.state.value = 100;              // Current (v3)
s.v3.v2.v1.state.value = 5;       // v1 level (flows through all)
s.v2.state.value = 50;            // v2 level (flows through v2 → v3)
```

**Type structure:**
```typescript
const s: Stream<number> & {
    state: State<number>;
    v1: Stream<number> & { state: State<number> };
    v2: Stream<number> & { 
        state: State<number>;
        v1: Stream<number> & { state: State<number> };
    };
    v3: Stream<number> & {
        state: State<number>;
        v2: Stream<number> & { ... };
    };
}
```

### Why snapshot is Revolutionary

**snapshot transforms a linear pipeline into a programmable control flow graph:**

- **Injection point** - Bypass upstream transformers
- **Observation point** - Tap into flow at any stage
- **Branching point** - Create parallel processing paths
- **Testing point** - Isolated testing of pipeline segments
- **State point** - Access capabilities at any level
- **Control flow** - Replay, catch, goto, checkpoint, undo/redo

**With 10 lines of code, snapshot enables:**
- Complex routing
- Multi-stage testing
- Parallel processing
- Time-travel debugging
- Surgical injection
- Multi-level observation
- Error recovery
- State management
- Undo/redo systems

**This is the killer feature that sets Stream apart from every other reactive library.**

## Universal Abstraction - The Agnostic Stack

**Stream is designed to be universal across all dimensions:**

### Language Agnostic

Same API across all languages:

```typescript
// TypeScript
const s = new Stream<number>()
  .pipe(state(0))
  .pipe(snapshot("v1"))
  .pipe(map(v => v * 2));
```

```python
# Python
s = Stream[int]() \
  .pipe(state(0)) \
  .pipe(snapshot("v1")) \
  .pipe(map(lambda v: v * 2))
```

```rust
// Rust
let s = Stream::new()
  .pipe(state(0))
  .pipe(snapshot("v1"))
  .pipe(map(|v| v * 2));
```

```go
// Go
s := NewStream[int]().
  Pipe(State(0)).
  Pipe(Snapshot("v1")).
  Pipe(Map(func(v int) int { return v * 2 }))
```

**Same mental model. Zero cognitive overhead when switching languages.**

### Platform Agnostic

Same execution strategies across all platforms:

- **Browser**: Web Workers
- **Node.js**: Worker Threads
- **Deno**: Web Workers
- **Bun**: Native threads
- **Python**: multiprocessing
- **Rust**: tokio tasks
- **Go**: goroutines

```typescript
// Same code, different platform
stream.pipe(parallel((x) => heavyComputation(x)))
```

### Paradigm Agnostic

Supports multiple paradigms in one pipeline:

```typescript
const result = new Stream<Data>()        // Event-Driven
  .pipe(zip(configStream))               // Dataflow
  .pipe(map(([data, config]) => ({       // Data-Driven
    value: data,
    predicate: config.filterFn
  })))
  .pipe(filter)                          // FRP
  .pipe(parallel(process))               // Parallel execution
  .listen(handler);                      // Event-Driven
```

### Framework Agnostic

Works with any framework:

- **React**: `useStream(stream)`
- **Vue**: `const value = ref(stream)`
- **Svelte**: `$: value = $stream`
- **Express**: `stream.listen(res.send)`
- **No framework**: Just works

### The Value Proposition

> **"Learn Stream once. Use it everywhere. Forever."**

**For developers:**
- One library to learn
- Works in every language they use
- Same patterns across frontend/backend
- No context switching

**For companies:**
- One training program
- Consistent codebase across languages
- Easy to hire (everyone knows Stream)
- Future-proof (language-agnostic)

**For the ecosystem:**
- No fragmentation (no RxJS vs RxPY vs RxJava)
- Shared knowledge base
- Cross-language patterns
- Universal best practices

### Historical Parallels

**Stream is like:**
- **SQL** - Same query language across all databases
- **HTTP** - Same protocol across all platforms
- **Git** - Same workflow across all languages
- **Docker** - Same containers across all systems

**Stream could become:**
> **The universal reactive primitive across all languages**

### Implementation Strategy

**Phase 1: Prove the concept (TypeScript)** ✅
- Get community feedback
- Refine patterns
- Establish best practices

**Phase 2: High-impact languages**
1. **Python** - ML/data science community
2. **Rust** - Systems programming, performance
3. **Go** - Backend services, cloud native

**Phase 3: Enterprise languages**
4. **Java** - Enterprise adoption
5. **C#** - .NET ecosystem
6. **Kotlin** - Modern JVM

**The concepts are universal. The innovations are real. The timing is right.**

## Key Insights

- **Stream is a runtime for reactive compositions** - 1 primitive, infinite patterns
- **Controller is enhanced AbortController** - It IS a Stream (pipeable lifecycle)
- **listen() is the bridge** - Converts lazy to hot, triggers execution
- **Capability preservation is automatic** - pipe() handles all merging
- **Execution strategies are primitives** - Compose with logic transformers
- **Self-referential pattern eliminates coordination** - Stream creates Stream
- **All values are valid** - undefined, null are data, not control flow
- **bind enables bi-directional sync** - Keep pipeline alive, automatic cleanup
- **snapshot is the killer feature** - Transforms linear pipelines into programmable control flow graphs
- **Universal abstraction** - Language, platform, paradigm, and framework agnostic
- **Learn once, use everywhere** - Same API across all languages and platforms
